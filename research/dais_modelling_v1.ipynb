{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature DF: (17646119, 11)\n",
      "Target DF: (17911332, 11)\n",
      "\n",
      "Feature columns: ['stock_id', 'time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\n",
      "\n",
      "Target columns: ['stock_id', 'time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\n",
      "\n",
      "Concat DF (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>740.03</td>\n",
       "      <td>740.29</td>\n",
       "      <td>740.0</td>\n",
       "      <td>740.30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>740.03</td>\n",
       "      <td>740.29</td>\n",
       "      <td>740.0</td>\n",
       "      <td>740.30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>740.05</td>\n",
       "      <td>740.29</td>\n",
       "      <td>740.0</td>\n",
       "      <td>740.30</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>740.05</td>\n",
       "      <td>740.29</td>\n",
       "      <td>740.0</td>\n",
       "      <td>740.30</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>740.06</td>\n",
       "      <td>740.36</td>\n",
       "      <td>740.0</td>\n",
       "      <td>740.39</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0      8382        6             1800.0      740.03      740.29       740.0   \n",
       "1      8382        6             1800.0      740.03      740.29       740.0   \n",
       "2      8382        6             1801.0      740.05      740.29       740.0   \n",
       "3      8382        6             1801.0      740.05      740.29       740.0   \n",
       "4      8382        6             1802.0      740.06      740.36       740.0   \n",
       "\n",
       "   ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "0      740.30          6          6        800         40  \n",
       "1      740.30          6          6        800         40  \n",
       "2      740.30         25          1         99         40  \n",
       "3      740.30         25          1         99         40  \n",
       "4      740.39        100         30        399          4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concat DF (tail):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35557446</th>\n",
       "      <td>104919</td>\n",
       "      <td>1199</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>362.73</td>\n",
       "      <td>362.74</td>\n",
       "      <td>362.72</td>\n",
       "      <td>362.75</td>\n",
       "      <td>200</td>\n",
       "      <td>1190</td>\n",
       "      <td>1200</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35557447</th>\n",
       "      <td>104919</td>\n",
       "      <td>1199</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>362.68</td>\n",
       "      <td>362.70</td>\n",
       "      <td>362.67</td>\n",
       "      <td>362.71</td>\n",
       "      <td>800</td>\n",
       "      <td>200</td>\n",
       "      <td>1600</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35557448</th>\n",
       "      <td>104919</td>\n",
       "      <td>1199</td>\n",
       "      <td>3597.0</td>\n",
       "      <td>362.69</td>\n",
       "      <td>362.70</td>\n",
       "      <td>362.68</td>\n",
       "      <td>362.71</td>\n",
       "      <td>200</td>\n",
       "      <td>900</td>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35557449</th>\n",
       "      <td>104919</td>\n",
       "      <td>1199</td>\n",
       "      <td>3598.0</td>\n",
       "      <td>362.72</td>\n",
       "      <td>362.73</td>\n",
       "      <td>362.71</td>\n",
       "      <td>362.74</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35557450</th>\n",
       "      <td>104919</td>\n",
       "      <td>1199</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>362.80</td>\n",
       "      <td>362.81</td>\n",
       "      <td>362.79</td>\n",
       "      <td>362.82</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          stock_id  time_id  seconds_in_bucket  bid_price1  ask_price1  \\\n",
       "35557446    104919     1199             3595.0      362.73      362.74   \n",
       "35557447    104919     1199             3596.0      362.68      362.70   \n",
       "35557448    104919     1199             3597.0      362.69      362.70   \n",
       "35557449    104919     1199             3598.0      362.72      362.73   \n",
       "35557450    104919     1199             3599.0      362.80      362.81   \n",
       "\n",
       "          bid_price2  ask_price2  bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "35557446      362.72      362.75        200       1190       1200       1600  \n",
       "35557447      362.67      362.71        800        200       1600       1400  \n",
       "35557448      362.68      362.71        200        900       1400       1400  \n",
       "35557449      362.71      362.74        200       1000        900        500  \n",
       "35557450      362.79      362.82        200        300        600        300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set path to local data directory\n",
    "folder_path = \"/Users/dais/Downloads/Optiver_additional data\"\n",
    "\n",
    "# Define file paths\n",
    "feature_path = os.path.join(folder_path, \"order_book_feature.parquet\")\n",
    "target_path = os.path.join(folder_path, \"order_book_target.parquet\")\n",
    "\n",
    "# Load parquet files (first 30 mins = feature, last 30 mins = target side of the hour)\n",
    "feature_df = pd.read_parquet(feature_path, engine='pyarrow')\n",
    "target_df = pd.read_parquet(target_path, engine='pyarrow')\n",
    "\n",
    "# Display dataset dimensions and column names\n",
    "print(\"Feature DF:\", feature_df.shape)\n",
    "print(\"Target DF:\", target_df.shape)\n",
    "print(\"\\nFeature columns:\", feature_df.columns.tolist())\n",
    "print(\"\\nTarget columns:\", target_df.columns.tolist())\n",
    "\n",
    "# Concatenating both DataFrames vertically (stacking feature + target rows)\n",
    "# Note: This doesn't align features and targets — it's just combining both halves of the hour\n",
    "combined_df = pd.concat([feature_df, target_df], axis=0)\n",
    "\n",
    "# Sort to organize by stock, time, and within-hour time buckets\n",
    "combined_df = combined_df.sort_values(by=['stock_id', 'time_id', 'seconds_in_bucket']).reset_index(drop=True)\n",
    "\n",
    "# Preview top and bottom of the stacked DataFrame\n",
    "print(\"\\nConcat DF (head):\")\n",
    "display(combined_df.head())\n",
    "\n",
    "print(\"\\nConcat DF (tail):\")\n",
    "display(combined_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>wap</th>\n",
       "      <th>spread_pct</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>depth_ratio</th>\n",
       "      <th>spread_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>740.160000</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>740.160000</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>740.280769</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>740.280769</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8382</td>\n",
       "      <td>6</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>740.290769</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id  seconds_in_bucket         wap  spread_pct  imbalance  \\\n",
       "0      8382        6             1800.0  740.160000    0.000351   0.000000   \n",
       "1      8382        6             1800.0  740.160000    0.000351   0.000000   \n",
       "2      8382        6             1801.0  740.280769    0.000324   0.923077   \n",
       "3      8382        6             1801.0  740.280769    0.000324   0.923077   \n",
       "4      8382        6             1802.0  740.290769    0.000405   0.538462   \n",
       "\n",
       "   depth_ratio  spread_variation  \n",
       "0     1.000000               NaN  \n",
       "1     1.000000          0.000000  \n",
       "2    25.000000          0.000016  \n",
       "3    25.000000          0.000016  \n",
       "4     3.333333          0.000033  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature engineering function to the combined DataFrame (includes both first + last 30 min)\n",
    "def compute_orderbook_features(df):\n",
    "    \"\"\"\n",
    "    Compute engineered order book features from raw order book snapshots.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Mid price and Weighted Average Price\n",
    "    df['mid_price'] = (df['bid_price1'] + df['ask_price1']) / 2\n",
    "    df['wap'] = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (\n",
    "        df['bid_size1'] + df['ask_size1']\n",
    "    )\n",
    "\n",
    "    # Spread and relative spread\n",
    "    df['bid_ask_spread'] = df['ask_price1'] - df['bid_price1']\n",
    "    df['spread_pct'] = df['bid_ask_spread'] / df['mid_price']\n",
    "\n",
    "    # Spread variation over time within the same time_id\n",
    "    df['spread_variation'] = df.groupby(['stock_id', 'time_id'])['spread_pct'].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).std()\n",
    "    )\n",
    "\n",
    "    # Order book imbalance and depth ratio\n",
    "    df['imbalance'] = (df['bid_size1'] - df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    df['depth_ratio'] = df['bid_size1'] / df['ask_size1'].replace(0, np.nan)\n",
    "\n",
    "    # Return only the engineered features\n",
    "    keep_cols = [\n",
    "        'stock_id', 'time_id', 'seconds_in_bucket',\n",
    "        'wap', 'spread_pct', 'imbalance', 'depth_ratio', 'spread_variation'\n",
    "    ]\n",
    "    return df[keep_cols]\n",
    "\n",
    "# Apply feature engineering to the combined order book data\n",
    "feature_engineered_df = compute_orderbook_features(combined_df)\n",
    "\n",
    "# Preview result\n",
    "feature_engineered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>time_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time  time_id\n",
       "0  2021-01-05  11:00:00       12\n",
       "1  2021-01-05  12:00:00       13\n",
       "2  2021-01-05  13:00:00       14\n",
       "3  2021-01-05  14:00:00       15\n",
       "4  2021-01-05  15:00:00       16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ref_path = os.path.join(folder_path, \"time_id_reference.csv\")\n",
    "time_ref_df = pd.read_csv(time_ref_path)\n",
    "time_ref_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine date and time into a full datetime column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>time_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-01-05 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-01-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>2021-01-05 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-01-05 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-01-05 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time  time_id            datetime\n",
       "0  2021-01-05  11:00:00       12 2021-01-05 11:00:00\n",
       "1  2021-01-05  12:00:00       13 2021-01-05 12:00:00\n",
       "2  2021-01-05  13:00:00       14 2021-01-05 13:00:00\n",
       "3  2021-01-05  14:00:00       15 2021-01-05 14:00:00\n",
       "4  2021-01-05  15:00:00       16 2021-01-05 15:00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "time_ref_df[\"datetime\"] = pd.to_datetime(time_ref_df[\"date\"] + \" \" + time_ref_df[\"time\"])\n",
    "time_ref_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time ID to Real Time Mapping\n",
    "NaT (Not a Time) means the merge didn’t find a matching time_id in time_ref_df\n",
    "For example, time_id 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-do the merge and keep only the new datetime column\n",
    "feature_engineered_df = pd.merge(\n",
    "    feature_engineered_df.drop(columns=[\"datetime\"], errors=\"ignore\"),  # just in case it already exists\n",
    "    time_ref_df[[\"time_id\", \"datetime\"]],\n",
    "    on=\"time_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "feature_engineered_df.head()\n",
    "feature_engineered_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split \n",
    "## Chronological time_id-based split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort just in case\n",
    "feature_engineered_df = feature_engineered_df.sort_values(by=\"time_id\")\n",
    "\n",
    "# Unique time_ids\n",
    "unique_ids = sorted(feature_engineered_df[\"time_id\"].unique())\n",
    "cutoff = int(len(unique_ids) * 0.8)\n",
    "\n",
    "# Train on earliest 80%, test on latest 20%\n",
    "train_ids = unique_ids[:cutoff]\n",
    "test_ids = unique_ids[cutoff:]\n",
    "\n",
    "train_df_timeid = feature_engineered_df[feature_engineered_df[\"time_id\"].isin(train_ids)]\n",
    "test_df_timeid = feature_engineered_df[feature_engineered_df[\"time_id\"].isin(test_ids)]\n",
    "\n",
    "print(\"TimeID Split:\")\n",
    "print(\"Train shape:\", train_df_timeid.shape)\n",
    "print(\"Test shape:\", test_df_timeid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with one stock \n",
    "Each stock has its own dynamics, so we usually train per stock\n",
    "\n",
    "Each stock might behave diffrently to diffrent models and will required diffrent tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with SPY XNAS\n",
    "spy_df = feature_engineered_df[feature_engineered_df[\"stock_id\"] == 50200].copy()\n",
    "print(spy_df.tail())\n",
    "\n",
    "# Check the datetime available\n",
    "spy_df[\"date_only\"] = spy_df[\"datetime\"].dt.date\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df.groupby(\"datetime\")[\"spread_pct\"].mean().plot(\n",
    "    figsize=(15,4), title=\"SPY: Spread % Over Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Compute log returns (per time_id)\n",
    "spy_df[\"log_return\"] = spy_df.groupby(\"time_id\")[\"wap\"].transform(lambda x: np.log(x / x.shift(1)))\n",
    "\n",
    "\n",
    "# Compute realized volatility per time_id\n",
    "rv_df = spy_df.groupby(\"time_id\")[\"log_return\"].agg(lambda x: np.sqrt(np.sum(x**2))).reset_index()\n",
    "\n",
    "rv_df = rv_df.rename(columns={\"log_return\": \"realized_volatility\"})\n",
    "\n",
    "#  Merge back into spy_df\n",
    "spy_df = pd.merge(spy_df, rv_df, on=\"time_id\", how=\"left\")\n",
    "\n",
    "# Plot volatility over time\n",
    "spy_df.groupby(\"datetime\")[\"realized_volatility\"].mean().plot(\n",
    "    figsize=(15, 4), title=\"SPY: Realized Volatility Over Time\"\n",
    ")\n",
    "plt.xlabel(\"Datetime\")\n",
    "plt.ylabel(\"Realized Volatility\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAV RV as baseline model\n",
    "## train/test split on time id 80/20 with rolling window (W=330, H=10, S=5) \n",
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function \n",
    "\n",
    "def evaluate_model(true, pred):\n",
    "    # Clip predicted values to avoid log(0) or division by 0\n",
    "    pred_clipped = np.clip(pred, 1e-8, None)\n",
    "    true = np.array(true)\n",
    "    \n",
    "    # MSE\n",
    "    mse = mean_squared_error(true, pred_clipped)\n",
    "\n",
    "    # QLIKE\n",
    "    try:\n",
    "        qlike_score = np.mean(np.log(pred_clipped**2) + (true**2) / (pred_clipped**2))\n",
    "    except Exception as e:\n",
    "        qlike_score = np.nan\n",
    "        print(\"QLIKE calculation failed:\", e)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.8f}\")\n",
    "    print(f\"Test QLIKE: {qlike_score:.8f}\")\n",
    "\n",
    "    return mse, qlike_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAV RV OLS\n",
    "# Prepare lagged HAV features\n",
    "hav_df = rv_df.copy()\n",
    "hav_df[\"rv_lag_1\"] = hav_df[\"realized_volatility\"].shift(1)\n",
    "hav_df[\"rv_lag_5\"] = hav_df[\"realized_volatility\"].shift(5)\n",
    "hav_df[\"rv_lag_10\"] = hav_df[\"realized_volatility\"].shift(10)\n",
    "hav_df = hav_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Set rolling window parameters\n",
    "W, H, S = 330, 10, 5  # Window size, forecast horizon, step size\n",
    "\n",
    "# Rolling window forecasting\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "for start in range(0, len(hav_df) - W - H + 1, S):\n",
    "    train_window = hav_df.iloc[start:start + W]\n",
    "    test_window = hav_df.iloc[start + W:start + W + H]\n",
    "\n",
    "    # Fit model on rolling window\n",
    "    X_train = sm.add_constant(train_window[[\"rv_lag_1\", \"rv_lag_5\", \"rv_lag_10\"]])\n",
    "    y_train = train_window[\"realized_volatility\"]\n",
    "    model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "    # Predict\n",
    "    X_test = sm.add_constant(test_window[[\"rv_lag_1\", \"rv_lag_5\", \"rv_lag_10\"]])\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_actuals.extend(test_window[\"realized_volatility\"].values)\n",
    "\n",
    "# Evaluate \n",
    "preds = np.array(all_preds)\n",
    "actuals = np.array(all_actuals)\n",
    "#call helper function\n",
    "mse_ols, qlike_ols = evaluate_model(actuals, preds)\n",
    "\n",
    "# Plot predicted and actual volatility\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(actuals, label=\"Actual RV\", color=\"blue\")\n",
    "plt.plot(preds, label=\"Predicted RV (Rolling HAV-RV)\", color=\"orange\")\n",
    "plt.title(f\"HAV-RV with Rolling Window (W={W}, H={H}, S={S})\\nMSE: {mse_ols:.6f}, QLIKE: {qlike_ols:.6f}\")\n",
    "plt.xlabel(\"Time ID (Rolling Forecast)\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAV RV WLS\n",
    "# Prepare lagged HAV features\n",
    "hav_df = rv_df.copy()\n",
    "hav_df[\"rv_lag_1\"] = hav_df[\"realized_volatility\"].shift(1)\n",
    "hav_df[\"rv_lag_5\"] = hav_df[\"realized_volatility\"].shift(5)\n",
    "hav_df[\"rv_lag_10\"] = hav_df[\"realized_volatility\"].shift(10)\n",
    "hav_df = hav_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Set rolling window parameters\n",
    "W, H, S = 330, 10, 5  # Window size, forecast horizon, step size\n",
    "\n",
    "# Rolling window forecasting\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "for start in range(0, len(hav_df) - W - H + 1, S):\n",
    "    train_window = hav_df.iloc[start:start + W]\n",
    "    test_window = hav_df.iloc[start + W:start + W + H]\n",
    "\n",
    "    # Compute weights (inverse of squared RV)\n",
    "    weights = 1 / (train_window[\"realized_volatility\"] ** 2 + 1e-8)  # add epsilon to avoid div by zero\n",
    "\n",
    "    # Fit WLS model on rolling window\n",
    "    X_train = sm.add_constant(train_window[[\"rv_lag_1\", \"rv_lag_5\", \"rv_lag_10\"]])\n",
    "    y_train = train_window[\"realized_volatility\"]\n",
    "    model = sm.WLS(y_train, X_train, weights=weights).fit()\n",
    "\n",
    "    # Predict\n",
    "    X_test = sm.add_constant(test_window[[\"rv_lag_1\", \"rv_lag_5\", \"rv_lag_10\"]])\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    all_preds.extend(preds)\n",
    "    all_actuals.extend(test_window[\"realized_volatility\"].values)\n",
    "\n",
    "# Evaluate \n",
    "preds = np.array(all_preds)\n",
    "actuals = np.array(all_actuals)\n",
    "mse_wls, qlike_wls = evaluate_model(actuals, preds)\n",
    "\n",
    "# Plot predicted and actual volatility\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(actuals, label=\"Actual RV\", color=\"blue\")\n",
    "plt.plot(preds, label=\"Predicted RV (Rolling HAV-WLS)\", color=\"green\")\n",
    "plt.title(f\"HAV-WLS with Rolling Window (W={W}, H={H}, S={S})\\nMSE: {mse_wls:.6f}, QLIKE: {qlike_wls:.6f}\")\n",
    "plt.xlabel(\"Time ID (Rolling Forecast)\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels\n",
    "#!pip install scikit-learn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
